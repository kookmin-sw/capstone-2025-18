from paddleocr import PaddleOCR
import cv2
import numpy as np
import random
from sklearn.cluster import KMeans
import os
import tempfile
from PIL import Image
import subprocess
import platform
import shutil

class TimetableImagePreprocessor():
    # def __init__(self):
        # OCR ì„¤ì •
        # ocr = PaddleOCR(
        #     use_angle_cls=True, # ì´ë¯¸ì§€ íšŒì „ ìë™ ë³´ì •
        #     lang='korean',  # ì˜ì–´,ìˆ«ìë„ ë™ì‹œ ì¸ì‹
        #     rec_algorithm='SVTR_LCNet',  # ì¸ì‹ë¥  ë†’ì´ê¸°
        #     det_db_box_thresh=0.5, # í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê¸°ì¤€ì  (0 ~ 1) : ë‚®ì„ìˆ˜ë¡ ë¯¼ê°
        #     drop_score=0.3, # ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’ : ì´ ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ë¬´ì‹œ
        #     show_log=False # ì½˜ì†” ë¡œê·¸ ì¶œë ¥ ë¹„í™œì„±í™”
        # )

    def read_image(self, path):
        self.img = cv2.imread(path)

    def make_temp_folder(self):
        self.temp_dir = tempfile.mkdtemp(prefix="cropped_boxes_")

    def cluster_colors_with_kmeans(self):
        """
        ì´ë¯¸ì§€ ìƒ‰ìƒ ì •ë³´ êµ°ì§‘í™” -> ìœ ì‚¬ ìƒ‰ìƒ ì˜ì—­ ì¶”ì¶œ
        :return: None
        """

        img_lab = cv2.cvtColor(self.img, cv2.COLOR_BGR2Lab) # ìƒ‰ìƒ êµ°ì§‘í™” : ìƒ‰ìƒì„ RGB -> Labìœ¼ë¡œ ë³€í™˜(ë°ê¸°, ìƒ‰ìƒ)
        self.h, self.w = self.img.shape[:2] # ì´ë¯¸ì§€ ë†’ì´, ë„ˆë¹„ ì¶”ì¶œ
        flat_img = img_lab.reshape((-1, 3)) # ì´ë¯¸ì§€ í‰íƒ„í™” (ê° í”½ì…€ ìƒ‰ìƒ êµ°ì§‘í™”)

        kmeans = KMeans(n_clusters=15, random_state=42, n_init=10) # ìƒ‰ìƒì„ n_clustersê°œë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ Kmeans ì‹¤í–‰
        self.labels = kmeans.fit_predict(flat_img) # í´ëŸ¬ìŠ¤í„°ë§(ê° í”½ì…€ ë¼ë²¨ë§)
        self.clustered = kmeans.cluster_centers_[self.labels].reshape((self.h, self.w, 3)).astype(np.uint8) # ë‹¤ì‹œ ì´ë¯¸ì§€í™”


    def detect_grid_lines(self, save_path=None):
        """
        íë¦° íšŒìƒ‰ ê²©ìì„ (ìˆ˜í‰/ìˆ˜ì§) ê²€ì¶œ ë° ì´ë¯¸ì§€ì— ì‹œê°í™”
        :param save_path: ì‹œê°í™”ëœ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (ì˜µì…˜)
        :return: None
        """
        gray = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        edges = cv2.Canny(blurred, 30, 100, apertureSize=3)

        lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi / 180, threshold=80,
                                minLineLength=200, maxLineGap=10)

        self.grid_lines = []  # ìˆ˜í‰/ìˆ˜ì§ ì„  ëª©ë¡
        self.grid_img = self.img.copy()

        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                if abs(x1 - x2) < 10 or abs(y1 - y2) < 10:  # ìˆ˜ì§ ë˜ëŠ” ìˆ˜í‰
                    self.grid_lines.append((x1, y1, x2, y2))
                    cv2.line(self.grid_img, (x1, y1), (x2, y2), (0, 255, 0), 1)

        # ì €ì¥ ê²½ë¡œ ì§€ì •
        if save_path:
            final_path = save_path
        else:
            final_path = os.path.join(self.temp_dir, "grid_overlay.png")

        cv2.imwrite(final_path, self.grid_img)
        print(f"âœ… ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {final_path}")

    def remove_duplicate_boxes(self, boxes, iou_threshold=0.95):
        """
        ì¤‘ë³µ ë°•ìŠ¤ ì œê±°
        :param boxes: ì¼ì • ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ (List)
        :param iou_threshold: ì–¼ë§ˆë‚˜ ê²¹ì¹˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨í• ì§€ ê¸°ì¤€ ê°’ (0~1)
        :return: kept : ì¤‘ë³µ ì œê±°ëœ boxes (List)
        """

        def iou(box1, box2):
            x1, y1, x2, y2 = box1
            x1_, y1_, x2_, y2_ = box2
            inter_x1 = max(x1, x1_)
            inter_y1 = max(y1, y1_)
            inter_x2 = min(x2, x2_)
            inter_y2 = min(y2, y2_)
            inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)  # ê²¹ì¹˜ëŠ” ë¶€ë¶„ ë©´ì 
            box1_area = (x2 - x1) * (y2 - y1)
            box2_area = (x2_ - x1_) * (y2_ - y1_)
            union_area = box1_area + box2_area - inter_area  # ì „ì²´ ë©´ì  (í•©ì§‘í•© - êµì§‘í•©)
            return inter_area / union_area if union_area else 0  # 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ë°•ìŠ¤ê°€ ì¼ì¹˜

        kept = []
        for box in boxes:
            if all(iou(box, k) < iou_threshold for k in kept):
                kept.append(box)  # ê²¹ì¹˜ì§€ ì•ŠëŠ” ë°•ìŠ¤ë§Œ ì €ì¥

        return kept

    def extract_text_boxes(self):
        """
        ì „ì²´ ìš”ì¼ì´ ë‹´ê²¨ìˆëŠ” ë°•ìŠ¤, ì „ì²´ ì‹œê°„ëŒ€ê°€ ë‹´ê²¨ìˆëŠ” ë°•ìŠ¤, ì¼ì •ë°•ìŠ¤ ì¶”ì¶œ
        :return: {
            "schedule_boxes": [(x1, y1, x2, y2)...],
            "day_word_boxes": [(x1, y1, x2, y2)...],
            "time_word_boxes": [(x1, y1, x2, y2)...]
        }
        """

        self.boxes = []
        self.day_word_boxes = []
        self.time_word_boxes = []

        for label in np.unique(self.labels):
            mask = (self.labels.reshape((self.h, self.w)) == label).astype(np.uint8) * 255
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for label in np.unique(self.labels):
            mask = (self.labels.reshape((self.h, self.w)) == label).astype(np.uint8) * 255
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for cnt in contours:
                x, y, bw, bh = cv2.boundingRect(cnt)
                area = bw * bh

                if area > 2000 and 50 < bw < self.w and 30 < bh < self.h:
                    # ìš”ì¼ í–‰
                    if y < self.h * 0.1 and bh < self.h * 0.07:
                        self.day_word_boxes.append((x, y, x + bw, y + bh))
                        continue

                    # ì‹œê°„ëŒ€ ì—´
                    elif x < self.w * 0.2 and bw < self.w * 0.1:
                        self.time_word_boxes.append((x, y, x + bw, y + bh))
                        continue

                    roi = self.img[y:y + bh, x:x + bw]
                    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                    _, roi_bin = cv2.threshold(roi_gray, 200, 255, cv2.THRESH_BINARY_INV)
                    if cv2.countNonZero(roi_bin) > 80:
                        self.boxes.append((x, y, x + bw, y + bh))

        self.boxes = self.remove_duplicate_boxes(self.boxes)

        return {
            "schedule_boxes": self.boxes,
            "day_word_boxes": self.day_word_boxes,
            "time_word_boxes": self.time_word_boxes
        }

    def save_temp_image(self):
        """
        ì¼ì • ë°•ìŠ¤, ìš”ì¼ ë°•ìŠ¤, ì‹œê°„ëŒ€ ë°•ìŠ¤ ì €ì¥ (ë¹ˆ ì´ë¯¸ì§€ ìë™ í•„í„°ë§)
        :return: self.temp_crop_dir : ì €ì¥ëœ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        """
        self.save_cropped_boxes(self.boxes, "box")
        self.save_cropped_boxes(self.day_word_boxes, "day")
        self.save_cropped_boxes(self.time_word_boxes, "time")
        return self.temp_dir

    def save_cropped_boxes(self, boxes, prefix):
        """
        ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ ì €ì¥ (ë¹ˆ ì´ë¯¸ì§€ ìë™ ì œì™¸)
        :param boxes: [(x1, y1, x2, y2), ...]
        :param prefix: ì €ì¥ íŒŒì¼ëª… ì•ì— ë¶™ì„ ë¬¸ìì—´ (box / day / time ë“±)
        """
        saved_idx = 1
        for (x1, y1, x2, y2) in sorted(boxes, key=lambda b: (b[1], b[0])):
            roi = self.img[y1:y2, x1:x2]
            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            _, bin_img = cv2.threshold(roi_gray, 240, 255, cv2.THRESH_BINARY_INV)
            non_zero = cv2.countNonZero(bin_img)

            if non_zero < 30:
                print(f"ğŸ—‘ï¸ ì‚­ì œë¨ (ë¹ˆ ì´ë¯¸ì§€): {prefix}_{saved_idx}.png")
                continue

            path = os.path.join(self.temp_dir, f"{prefix}_{saved_idx:02}.png")
            cv2.imwrite(path, roi)
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {path}")
            saved_idx += 1


    def open_folder(self):
        """
        ì €ì¥ëœ í´ë”ë¥¼ OSì— ë§ê²Œ ìë™ìœ¼ë¡œ ì—°ë‹¤ (Mac ê¸°ì¤€: Finder ì—´ê¸°).
        """
        if platform.system() == "Darwin":  # macOS
            subprocess.run(["open", self.temp_dir])
        elif platform.system() == "Windows":
            os.startfile(self.temp_dir)
        elif platform.system() == "Linux":
            subprocess.run(["xdg-open", self.temp_dir])
        else:
            print("âš ï¸ ìë™ í´ë” ì—´ê¸° ê¸°ëŠ¥ì€ ì´ ìš´ì˜ì²´ì œì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    def clean_temp_files(self):
        try:
            shutil.rmtree(self.temp_dir)
            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ì‚­ì œë¨: {self.temp_dir}")
        except Exception as e:
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {self.temp_dir} ({e})")

    def preprocess(self, img_path):
        self.read_image(img_path)
        self.cluster_colors_with_kmeans()
        self.make_temp_folder()
        # self.detect_grid_lines()
        self.extract_text_boxes()
        self.save_temp_image()
        # self.delete_empty_images()
        # self.open_folder()

        return self.temp_dir




# test = TimetableImagePreprocessor()
# test.preprocess("sample_img/sample4.png")
